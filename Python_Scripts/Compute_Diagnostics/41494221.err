2023-02-12 18:34:02,227 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-02-12 18:34:02,264 - distributed.scheduler - INFO - State start
2023-02-12 18:34:02,269 - distributed.scheduler - INFO -   Scheduler at:   tcp://172.17.1.18:43467
2023-02-12 18:34:02,269 - distributed.scheduler - INFO -   dashboard at:                     :8787
2023-02-12 18:34:02,285 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:37326
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:37326
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:38999
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:38999
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:39046
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:39046
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:33826
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:33826
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          6
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:36165
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          9
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:35024
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:34788
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:34788
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:34412
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:34412
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                         13
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:46292
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          2
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:37768
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:40669
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:36165
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          7
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                         11
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:34878
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:33098
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:33098
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:34593
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:37768
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          5
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:43321
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                         10
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:36295
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:44761
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:44761
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:34969
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:38183
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-1nevqp80
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-64cwo_lb
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-_xjr9l7a
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                         15
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:36218
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-xnikvuog
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:34969
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-h0b0zf8a
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:34765
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-w8uj6e91
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-rb2pv1rw
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                         14
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:44326
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          3
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:36226
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-rowd7w4v
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:34765
2023-02-12 18:34:02,286 - distributed.worker - INFO -           Worker name:                          8
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-_ber270m
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -          dashboard at:          172.17.1.19:36801
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-clsl61ym
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-y9dhh00i
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-h3ihwr34
2023-02-12 18:34:02,286 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,288 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:35585
2023-02-12 18:34:02,288 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:35585
2023-02-12 18:34:02,288 - distributed.worker - INFO -           Worker name:                          4
2023-02-12 18:34:02,288 - distributed.worker - INFO -          dashboard at:          172.17.1.19:34442
2023-02-12 18:34:02,288 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,288 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,288 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,288 - distributed.worker - INFO -       Start worker at:    tcp://172.17.1.19:39634
2023-02-12 18:34:02,288 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,288 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-e9fubyoc
2023-02-12 18:34:02,288 - distributed.worker - INFO -          Listening to:    tcp://172.17.1.19:39634
2023-02-12 18:34:02,288 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,288 - distributed.worker - INFO -           Worker name:                         12
2023-02-12 18:34:02,288 - distributed.worker - INFO -          dashboard at:          172.17.1.19:43498
2023-02-12 18:34:02,288 - distributed.worker - INFO - Waiting to connect to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,288 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,288 - distributed.worker - INFO -               Threads:                          1
2023-02-12 18:34:02,288 - distributed.worker - INFO -                Memory:                   3.91 GiB
2023-02-12 18:34:02,288 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space-7053462/worker-4zzybpk5
2023-02-12 18:34:02,288 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,291 - distributed.scheduler - INFO - Receive client connection: Client-d27892ab-ab03-11ed-bada-506b4b091354
2023-02-12 18:34:02,303 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:57568
2023-02-12 18:34:02,306 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:34969', name: 3, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,310 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,310 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,310 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:34969
2023-02-12 18:34:02,312 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50244
2023-02-12 18:34:02,315 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:37326', name: 9, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,316 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:37326
2023-02-12 18:34:02,316 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50226
2023-02-12 18:34:02,316 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,317 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,317 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:44761', name: 14, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,317 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:44761
2023-02-12 18:34:02,317 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50242
2023-02-12 18:34:02,317 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,318 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:34765', name: 8, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,318 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,318 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,318 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:34765
2023-02-12 18:34:02,318 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50246
2023-02-12 18:34:02,319 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,319 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:36165', name: 7, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,319 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:36165
2023-02-12 18:34:02,319 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50234
2023-02-12 18:34:02,320 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:33826', name: 6, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,320 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,320 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,320 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:33826
2023-02-12 18:34:02,320 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50228
2023-02-12 18:34:02,321 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:39046', name: 2, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,321 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,321 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,321 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,321 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:39046
2023-02-12 18:34:02,321 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50230
2023-02-12 18:34:02,321 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:34788', name: 10, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,321 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,322 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,322 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,322 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:34788
2023-02-12 18:34:02,322 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50236
2023-02-12 18:34:02,322 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:33098', name: 15, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,322 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,322 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,322 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,323 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:33098
2023-02-12 18:34:02,323 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50240
2023-02-12 18:34:02,322 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,323 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,323 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:34412', name: 11, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,323 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,323 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,323 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,323 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:34412
2023-02-12 18:34:02,323 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50232
2023-02-12 18:34:02,324 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,324 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:38999', name: 13, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,324 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,324 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,324 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,324 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:38999
2023-02-12 18:34:02,324 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50224
2023-02-12 18:34:02,325 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:37768', name: 5, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,325 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,325 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,325 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,325 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:37768
2023-02-12 18:34:02,325 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50238
2023-02-12 18:34:02,326 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,326 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,326 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,327 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,340 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:35585', name: 4, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,340 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:35585
2023-02-12 18:34:02,341 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50248
2023-02-12 18:34:02,341 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.17.1.19:39634', name: 12, status: init, memory: 0, processing: 0>
2023-02-12 18:34:02,341 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,341 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,341 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.1.19:39634
2023-02-12 18:34:02,341 - distributed.core - INFO - Starting established connection to tcp://172.17.1.19:50250
2023-02-12 18:34:02,342 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
2023-02-12 18:34:02,342 - distributed.worker - INFO -         Registered to:    tcp://172.17.1.18:43467
2023-02-12 18:34:02,342 - distributed.worker - INFO - -------------------------------------------------
2023-02-12 18:34:02,343 - distributed.core - INFO - Starting established connection to tcp://172.17.1.18:43467
slurmstepd: error: Detected 1 oom-kill event(s) in StepId=41494221.0. Some of your processes may have been killed by the cgroup out-of-memory handler.
srun: error: host387: task 0: Out Of Memory
[proxy:0:1@host388.jc.rl.ac.uk] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:899): assert (!closed) failed
[proxy:0:1@host388.jc.rl.ac.uk] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status
[proxy:0:1@host388.jc.rl.ac.uk] main (pm/pmiserv/pmip.c:171): demux engine error waiting for event
srun: error: host388: task 1: Exited with exit code 7
[mpiexec@host387.jc.rl.ac.uk] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:73): one of the processes terminated badly; aborting
[mpiexec@host387.jc.rl.ac.uk] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:21): launcher returned error waiting for completion
[mpiexec@host387.jc.rl.ac.uk] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:179): launcher returned error waiting for completion
[mpiexec@host387.jc.rl.ac.uk] main (ui/mpich/mpiexec.c:325): process manager error waiting for completion
slurmstepd: error: Detected 1 oom-kill event(s) in StepId=41494221.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.
